{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Groq API Key -- put GROQ API KEY HERE\n",
        "!pip install groq"
      ],
      "metadata": {
        "id": "TALroMBDuh1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf5e497-68c1-4d97-975e-52cbce7d1ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "import base64\n",
        "import re\n",
        "from datetime import datetime\n",
        "from groq import Groq\n",
        "\n",
        "class SimpleDrivingAssistant:\n",
        "    def __init__(self, video_path, groq_api_key, output_dir=\"output\", frame_interval=1.0):\n",
        "        \"\"\"\n",
        "        Initialize the simple driving assistant.\n",
        "\n",
        "        Args:\n",
        "            video_path: Path to the input video file\n",
        "            groq_api_key: Your Groq API key\n",
        "            output_dir: Directory to save processed frames and descriptions\n",
        "            frame_interval: Interval in seconds between frames to process\n",
        "        \"\"\"\n",
        "        self.video_path = video_path\n",
        "        self.groq_api_key = groq_api_key\n",
        "        self.client = Groq(api_key=groq_api_key)\n",
        "        self.output_dir = output_dir\n",
        "        self.frame_interval = frame_interval\n",
        "        self.analysis_results = []\n",
        "\n",
        "        # Create output directories\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        self.frames_dir = os.path.join(output_dir, \"frames\")\n",
        "        if not os.path.exists(self.frames_dir):\n",
        "            os.makedirs(self.frames_dir)\n",
        "\n",
        "    def extract_frames(self):\n",
        "        \"\"\"Extract frames from video at specified intervals\"\"\"\n",
        "        cap = cv2.VideoCapture(self.video_path)\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            raise ValueError(f\"Could not open video file: {self.video_path}\")\n",
        "\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        duration = total_frames / fps\n",
        "\n",
        "        print(f\"Video FPS: {fps}\")\n",
        "        print(f\"Total frames: {total_frames}\")\n",
        "        print(f\"Duration: {duration:.2f} seconds\")\n",
        "\n",
        "        # Calculate frame indices to extract\n",
        "        frame_indices = []\n",
        "        for second in range(int(duration)):\n",
        "            frame_indices.append(int(second * fps))\n",
        "\n",
        "        # Extract frames\n",
        "        frame_paths = []\n",
        "        for i, frame_idx in enumerate(frame_indices):\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                print(f\"Failed to read frame at index {frame_idx}\")\n",
        "                continue\n",
        "\n",
        "            # Save frame\n",
        "            frame_path = os.path.join(self.frames_dir, f\"frame_{i:04d}.jpg\")\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "            frame_paths.append((frame_path, i))\n",
        "\n",
        "            # Print progress\n",
        "            print(f\"Extracted frame {i+1}/{len(frame_indices)} at time {i}s\")\n",
        "\n",
        "        cap.release()\n",
        "        return frame_paths\n",
        "\n",
        "    def get_simple_analysis(self, image_path):\n",
        "        \"\"\"\n",
        "        Get simple analysis from Groq focusing only on key driving elements.\n",
        "\n",
        "        Args:\n",
        "            image_path: Path to the image file\n",
        "\n",
        "        Returns:\n",
        "            Simple analysis dict\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Read image file and encode as base64\n",
        "            with open(image_path, \"rb\") as f:\n",
        "                image_data = f.read()\n",
        "                base64_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
        "\n",
        "            # Format as data URL\n",
        "            frame_data = f\"data:image/jpeg;base64,{base64_image}\"\n",
        "\n",
        "            # Call Groq API with focused prompt\n",
        "            chat_completion = self.client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            {\"type\": \"text\", \"text\": \"\"\"Analyze this driving scene and respond with ONLY a JSON object in this exact format:\n",
        "                            {\n",
        "                                \"road_signs\": [\"description of each sign visible\"],\n",
        "                                \"intersections\": [\"description of upcoming intersections\"],\n",
        "                                \"pedestrians\": [\"location of pedestrians\", \"etc\"],\n",
        "                                \"vehicles\": [\"cars in front\", \"oncoming traffic\", \"etc\"],\n",
        "                                \"lane_status\": \"brief description of lane positioning\",\n",
        "                                \"immediate_hazards\": [\"description of any immediate hazards\"]\n",
        "                            }\n",
        "\n",
        "                            Keep your responses short and focused on what you can actually see.\n",
        "                            If you don't see any of these elements, use an empty array [].\n",
        "                            The lane_status should always be a string.\n",
        "                            DO NOT include any additional text before or after the JSON.\"\"\"},\n",
        "                            {\n",
        "                                \"type\": \"image_url\",\n",
        "                                \"image_url\": {\n",
        "                                    \"url\": frame_data,\n",
        "                                },\n",
        "                            },\n",
        "                        ],\n",
        "                    }\n",
        "                ],\n",
        "                model=\"llama-3.2-11b-vision-preview\",\n",
        "            )\n",
        "\n",
        "            response_text = chat_completion.choices[0].message.content.strip()\n",
        "\n",
        "            # Try to parse the JSON response\n",
        "            try:\n",
        "                # Find JSON in the response (in case there's extra text)\n",
        "                json_start = response_text.find('{')\n",
        "                json_end = response_text.rfind('}') + 1\n",
        "\n",
        "                if json_start >= 0 and json_end > json_start:\n",
        "                    json_str = response_text[json_start:json_end]\n",
        "\n",
        "                    # Fix some common JSON errors that might be in the response\n",
        "                    # 1. Fix unescaped quotes in strings\n",
        "                    json_str = json_str.replace('\"[\"', '[\"')\n",
        "                    json_str = json_str.replace('\"]\"', '\"]')\n",
        "                    json_str = json_str.replace('\", \"', '\", \"')\n",
        "\n",
        "                    # 2. Replace any doubled quotes with single quotes\n",
        "                    json_str = json_str.replace('\"\"', '\"')\n",
        "\n",
        "                    # Try to parse the fixed JSON\n",
        "                    try:\n",
        "                        analysis = json.loads(json_str)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error parsing JSON: {str(e)}\")\n",
        "                        print(f\"Received: {json_str}\")\n",
        "                        # Fallback with empty structure\n",
        "                        analysis = {\n",
        "                            \"road_signs\": [],\n",
        "                            \"intersections\": [],\n",
        "                            \"pedestrians\": [],\n",
        "                            \"vehicles\": [],\n",
        "                            \"lane_status\": \"Unknown\",\n",
        "                            \"immediate_hazards\": []\n",
        "                        }\n",
        "\n",
        "                    # Ensure all required keys exist\n",
        "                    required_keys = [\"road_signs\", \"intersections\", \"pedestrians\",\n",
        "                                    \"vehicles\", \"lane_status\", \"immediate_hazards\"]\n",
        "                    for key in required_keys:\n",
        "                        if key not in analysis:\n",
        "                            if key == \"lane_status\":\n",
        "                                analysis[key] = \"Unknown\"\n",
        "                            else:\n",
        "                                analysis[key] = []\n",
        "                else:\n",
        "                    # Fallback with empty structure\n",
        "                    analysis = {\n",
        "                        \"road_signs\": [],\n",
        "                        \"intersections\": [],\n",
        "                        \"pedestrians\": [],\n",
        "                        \"vehicles\": [],\n",
        "                        \"lane_status\": \"Unknown\",\n",
        "                        \"immediate_hazards\": []\n",
        "                    }\n",
        "            except Exception as json_error:\n",
        "                print(f\"Error parsing JSON: {str(json_error)}\")\n",
        "                print(f\"Received: {response_text}\")\n",
        "                analysis = {\n",
        "                    \"road_signs\": [],\n",
        "                    \"intersections\": [],\n",
        "                    \"pedestrians\": [],\n",
        "                    \"vehicles\": [],\n",
        "                    \"lane_status\": f\"Unknown\",\n",
        "                    \"immediate_hazards\": []\n",
        "                }\n",
        "\n",
        "            return analysis\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting analysis: {str(e)}\")\n",
        "            return {\n",
        "                \"road_signs\": [],\n",
        "                \"intersections\": [],\n",
        "                \"pedestrians\": [],\n",
        "                \"vehicles\": [],\n",
        "                \"lane_status\": f\"Error: {str(e)}\",\n",
        "                \"immediate_hazards\": []\n",
        "            }\n",
        "\n",
        "    def process_video(self):\n",
        "        \"\"\"Process the video and generate simple analysis for all frames\"\"\"\n",
        "        print(f\"Processing video: {self.video_path}\")\n",
        "\n",
        "        # Extract frames\n",
        "        frame_paths = self.extract_frames()\n",
        "\n",
        "        # Get analysis for each frame\n",
        "        for i, (frame_path, second) in enumerate(frame_paths):\n",
        "            print(f\"Getting analysis for frame {i+1}/{len(frame_paths)} at {second}s\")\n",
        "\n",
        "            # Get analysis\n",
        "            analysis = self.get_simple_analysis(frame_path)\n",
        "\n",
        "            # Store analysis with timestamp\n",
        "            self.analysis_results.append({\n",
        "                \"frame_index\": i,\n",
        "                \"timestamp\": second,\n",
        "                \"frame_path\": frame_path,\n",
        "                \"analysis\": analysis\n",
        "            })\n",
        "\n",
        "            # Save analysis to file periodically\n",
        "            if i % 5 == 0 or i == len(frame_paths) - 1:\n",
        "                self.save_analysis()\n",
        "\n",
        "            # Add a small delay to avoid API rate limits\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        return self.analysis_results\n",
        "\n",
        "    def save_analysis(self):\n",
        "        \"\"\"Save analysis to a JSON file\"\"\"\n",
        "        output_file = os.path.join(self.output_dir, \"driving_analysis.json\")\n",
        "        with open(output_file, \"w\") as f:\n",
        "            json.dump(self.analysis_results, f, indent=2)\n",
        "        print(f\"Saved analysis to {output_file}\")\n",
        "\n",
        "    def create_output_video(self, output_video_path=None):\n",
        "        \"\"\"\n",
        "        Create a new video with simple driving information overlay\n",
        "\n",
        "        Args:\n",
        "            output_video_path: Path for the output video file\n",
        "        \"\"\"\n",
        "        if not output_video_path:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            output_video_path = os.path.join(self.output_dir, f\"simple_driving_assistant_{timestamp}.mp4\")\n",
        "\n",
        "        # Open the input video\n",
        "        cap = cv2.VideoCapture(self.video_path)\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            raise ValueError(f\"Could not open video file: {self.video_path}\")\n",
        "\n",
        "        # Get video properties\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        # Create video writer\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "        # Define colors\n",
        "        COLORS = {\n",
        "            \"text_background\": (0, 0, 0),\n",
        "            \"text\": (255, 255, 255),\n",
        "            \"hazard\": (0, 0, 255),   # Red\n",
        "            \"sign\": (0, 255, 255),   # Yellow\n",
        "            \"normal\": (255, 255, 255) # White\n",
        "        }\n",
        "\n",
        "        # Process each frame\n",
        "        frame_count = 0\n",
        "        current_analysis = None\n",
        "        current_analysis_index = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Get current timestamp in seconds\n",
        "            timestamp = frame_count / fps\n",
        "\n",
        "            # Check if we need to update the analysis\n",
        "            if current_analysis_index < len(self.analysis_results):\n",
        "                if timestamp >= self.analysis_results[current_analysis_index][\"timestamp\"]:\n",
        "                    current_analysis = self.analysis_results[current_analysis_index][\"analysis\"]\n",
        "                    current_analysis_index += 1\n",
        "\n",
        "            # If we have analysis data, overlay it on the frame\n",
        "            if current_analysis:\n",
        "                # Create a copy of the frame\n",
        "                display_frame = frame.copy()\n",
        "\n",
        "                # Add semi-transparent overlay at the bottom\n",
        "                overlay = display_frame.copy()\n",
        "                cv2.rectangle(overlay, (0, height-130), (width, height), COLORS[\"text_background\"], -1)\n",
        "                alpha = 0.7  # Transparency factor\n",
        "                cv2.addWeighted(overlay, alpha, display_frame, 1-alpha, 0, display_frame)\n",
        "\n",
        "                # Add lane status\n",
        "                cv2.putText(\n",
        "                    display_frame,\n",
        "                    f\"Lane: {current_analysis['lane_status']}\",\n",
        "                    (20, height-100),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.6,\n",
        "                    COLORS[\"normal\"],\n",
        "                    1\n",
        "                )\n",
        "\n",
        "                # Add road signs with type checking\n",
        "                if current_analysis[\"road_signs\"]:\n",
        "                    # Check if road_signs is a list or other type\n",
        "                    if isinstance(current_analysis[\"road_signs\"], list):\n",
        "                        # Convert any non-string elements to strings\n",
        "                        sign_items = []\n",
        "                        for item in current_analysis[\"road_signs\"][:2]:\n",
        "                            if isinstance(item, str):\n",
        "                                sign_items.append(item)\n",
        "                            elif isinstance(item, (dict, list)):\n",
        "                                sign_items.append(str(item))\n",
        "                        signs_text = \"Signs: \" + \", \".join(sign_items)\n",
        "                    else:\n",
        "                        # Handle case where road_signs is not a list\n",
        "                        signs_text = \"Signs: \" + str(current_analysis[\"road_signs\"])\n",
        "\n",
        "                    cv2.putText(\n",
        "                        display_frame,\n",
        "                        signs_text,\n",
        "                        (20, height-75),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.6,\n",
        "                        COLORS[\"sign\"],\n",
        "                        1\n",
        "                    )\n",
        "\n",
        "                # Add intersections with type checking\n",
        "                if current_analysis[\"intersections\"]:\n",
        "                    # Check if intersections is a list or other type\n",
        "                    if isinstance(current_analysis[\"intersections\"], list):\n",
        "                        # Convert any non-string elements to strings\n",
        "                        intersection_items = []\n",
        "                        for item in current_analysis[\"intersections\"][:1]:\n",
        "                            if isinstance(item, str):\n",
        "                                intersection_items.append(item)\n",
        "                            elif isinstance(item, (dict, list)):\n",
        "                                intersection_items.append(str(item))\n",
        "                        intersections_text = \"Intersection: \" + \", \".join(intersection_items)\n",
        "                    else:\n",
        "                        # Handle case where intersections is not a list\n",
        "                        intersections_text = \"Intersection: \" + str(current_analysis[\"intersections\"])\n",
        "\n",
        "                    cv2.putText(\n",
        "                        display_frame,\n",
        "                        intersections_text,\n",
        "                        (20, height-50),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.6,\n",
        "                        COLORS[\"sign\"],\n",
        "                        1\n",
        "                    )\n",
        "\n",
        "                # Add vehicles and pedestrians info\n",
        "                vehicles_text = \"Vehicles: \"\n",
        "                if current_analysis[\"vehicles\"]:\n",
        "                    # Check if vehicles is a list or other type\n",
        "                    if isinstance(current_analysis[\"vehicles\"], list):\n",
        "                        # Convert any non-string elements to strings\n",
        "                        vehicle_items = []\n",
        "                        for item in current_analysis[\"vehicles\"][:2]:\n",
        "                            if isinstance(item, str):\n",
        "                                vehicle_items.append(item)\n",
        "                            elif isinstance(item, (dict, list)):\n",
        "                                vehicle_items.append(str(item))\n",
        "                        vehicles_text += \", \".join(vehicle_items)\n",
        "                    else:\n",
        "                        # Handle case where vehicles is not a list\n",
        "                        vehicles_text += str(current_analysis[\"vehicles\"])\n",
        "                else:\n",
        "                    vehicles_text += \"None detected\"\n",
        "\n",
        "                cv2.putText(\n",
        "                    display_frame,\n",
        "                    vehicles_text,\n",
        "                    (width//2, height-75),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.6,\n",
        "                    COLORS[\"normal\"],\n",
        "                    1\n",
        "                )\n",
        "\n",
        "                # Add pedestrians info with type checking\n",
        "                pedestrians_text = \"Pedestrians: \"\n",
        "                if current_analysis[\"pedestrians\"]:\n",
        "                    # Check if pedestrians is a list or other type\n",
        "                    if isinstance(current_analysis[\"pedestrians\"], list):\n",
        "                        # Convert any non-string elements to strings\n",
        "                        pedestrian_items = []\n",
        "                        for item in current_analysis[\"pedestrians\"][:2]:\n",
        "                            if isinstance(item, str):\n",
        "                                pedestrian_items.append(item)\n",
        "                            elif isinstance(item, (dict, list)):\n",
        "                                pedestrian_items.append(str(item))\n",
        "                        pedestrians_text += \", \".join(pedestrian_items)\n",
        "                    else:\n",
        "                        # Handle case where pedestrians is not a list\n",
        "                        pedestrians_text += str(current_analysis[\"pedestrians\"])\n",
        "                else:\n",
        "                    pedestrians_text += \"None detected\"\n",
        "\n",
        "                cv2.putText(\n",
        "                    display_frame,\n",
        "                    pedestrians_text,\n",
        "                    (width//2, height-50),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.6,\n",
        "                    COLORS[\"normal\"],\n",
        "                    1\n",
        "                )\n",
        "\n",
        "                # Add hazards with type checking\n",
        "                if current_analysis[\"immediate_hazards\"]:\n",
        "                    # Check if immediate_hazards is a list or other type\n",
        "                    if isinstance(current_analysis[\"immediate_hazards\"], list):\n",
        "                        # Convert any non-string elements to strings\n",
        "                        hazard_items = []\n",
        "                        for item in current_analysis[\"immediate_hazards\"]:\n",
        "                            if isinstance(item, str):\n",
        "                                hazard_items.append(item)\n",
        "                            elif isinstance(item, (dict, list)):\n",
        "                                hazard_items.append(str(item))\n",
        "                        hazards_text = \"CAUTION: \" + \", \".join(hazard_items)\n",
        "                    else:\n",
        "                        # Handle case where immediate_hazards is not a list\n",
        "                        hazards_text = \"CAUTION: \" + str(current_analysis[\"immediate_hazards\"])\n",
        "\n",
        "                    cv2.putText(\n",
        "                        display_frame,\n",
        "                        hazards_text,\n",
        "                        (20, height-25),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.6,\n",
        "                        COLORS[\"hazard\"],\n",
        "                        2\n",
        "                    )\n",
        "\n",
        "                # Write the modified frame\n",
        "                out.write(display_frame)\n",
        "            else:\n",
        "                # Write the original frame if no analysis is available\n",
        "                out.write(frame)\n",
        "\n",
        "            # Update frame count\n",
        "            frame_count += 1\n",
        "\n",
        "            # Print progress\n",
        "            if frame_count % 100 == 0:\n",
        "                print(f\"Processed {frame_count}/{total_frames} frames ({frame_count/total_frames*100:.1f}%)\")\n",
        "\n",
        "        # Release resources\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        print(f\"Output video saved to: {output_video_path}\")\n",
        "        return output_video_path"
      ],
      "metadata": {
        "id": "p8KCn78KsH71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage example\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with your actual values\n",
        "    video_path = \"/content/output (13).mp4\"\n",
        "    groq_api_key = \"Put GROQ API KEY HERE\"\n",
        "\n",
        "    # Create the assistant\n",
        "    assistant = SimpleDrivingAssistant(\n",
        "        video_path=video_path,\n",
        "        groq_api_key=groq_api_key,\n",
        "        output_dir=\"driving_assistant_output\"\n",
        "    )\n",
        "\n",
        "    # Process the video\n",
        "    assistant.process_video()\n",
        "\n",
        "    # Create output video with information overlay\n",
        "    assistant.create_output_video()"
      ],
      "metadata": {
        "id": "fwIvxvfHvcbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ea4cdb-a2fe-4a6e-d2d1-610bf6eeed49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video: /content/output (13).mp4\n",
            "Video FPS: 30.0\n",
            "Total frames: 576\n",
            "Duration: 19.20 seconds\n",
            "Extracted frame 1/19 at time 0s\n",
            "Extracted frame 2/19 at time 1s\n",
            "Extracted frame 3/19 at time 2s\n",
            "Extracted frame 4/19 at time 3s\n",
            "Extracted frame 5/19 at time 4s\n",
            "Extracted frame 6/19 at time 5s\n",
            "Extracted frame 7/19 at time 6s\n",
            "Extracted frame 8/19 at time 7s\n",
            "Extracted frame 9/19 at time 8s\n",
            "Extracted frame 10/19 at time 9s\n",
            "Extracted frame 11/19 at time 10s\n",
            "Extracted frame 12/19 at time 11s\n",
            "Extracted frame 13/19 at time 12s\n",
            "Extracted frame 14/19 at time 13s\n",
            "Extracted frame 15/19 at time 14s\n",
            "Extracted frame 16/19 at time 15s\n",
            "Extracted frame 17/19 at time 16s\n",
            "Extracted frame 18/19 at time 17s\n",
            "Extracted frame 19/19 at time 18s\n",
            "Getting analysis for frame 1/19 at 0s\n",
            "Saved analysis to driving_assistant_output/driving_analysis.json\n",
            "Getting analysis for frame 2/19 at 1s\n",
            "Getting analysis for frame 3/19 at 2s\n",
            "Getting analysis for frame 4/19 at 3s\n",
            "Getting analysis for frame 5/19 at 4s\n",
            "Error parsing JSON: Expecting ',' delimiter: line 1 column 141 (char 140)\n",
            "Received: {\"road_signs\": [], \"intersections\": [\"Roundabout up ahead.\"] , \"pedestrians\": [], \"vehicles\": [\"Two cars approaching in the opposite lane\"] \", \"lane_status\": \"Single lane on the right side, merging with two lanes of opposing traffic.\", \"immediate_hazards\": []}\n",
            "Getting analysis for frame 6/19 at 5s\n",
            "Saved analysis to driving_assistant_output/driving_analysis.json\n",
            "Getting analysis for frame 7/19 at 6s\n",
            "Getting analysis for frame 8/19 at 7s\n",
            "Getting analysis for frame 9/19 at 8s\n",
            "Getting analysis for frame 10/19 at 9s\n",
            "Getting analysis for frame 11/19 at 10s\n",
            "Saved analysis to driving_assistant_output/driving_analysis.json\n",
            "Getting analysis for frame 12/19 at 11s\n",
            "Getting analysis for frame 13/19 at 12s\n",
            "Getting analysis for frame 14/19 at 13s\n",
            "Getting analysis for frame 15/19 at 14s\n",
            "Getting analysis for frame 16/19 at 15s\n",
            "Saved analysis to driving_assistant_output/driving_analysis.json\n",
            "Getting analysis for frame 17/19 at 16s\n",
            "Getting analysis for frame 18/19 at 17s\n",
            "Getting analysis for frame 19/19 at 18s\n",
            "Saved analysis to driving_assistant_output/driving_analysis.json\n",
            "Processed 100/576 frames (17.4%)\n",
            "Processed 200/576 frames (34.7%)\n",
            "Processed 300/576 frames (52.1%)\n",
            "Processed 400/576 frames (69.4%)\n",
            "Processed 500/576 frames (86.8%)\n",
            "Output video saved to: driving_assistant_output/simple_driving_assistant_20250301_031236.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWpaUfrq2w9C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}